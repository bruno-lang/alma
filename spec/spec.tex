\documentclass[10pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{enumitem}
\usepackage{listings}
\usepackage{color}
\usepackage{inconsolata}

\newlist{rulelist}{description}{2}
\setlist[rulelist]{leftmargin=6.5em,style=nextline,font=\bf\tt}

\lstset{
  basicstyle=\footnotesize\ttfamily,
  breaklines=true,
  keywordstyle=\color{blue}
}

\begin{document}
\lstset{language=Haskell}
\title{Formal Grammars as Data and Solvers}
\author{Jan Bernitt}
\date{\today}
\maketitle

\begin{abstract}
\noindent Specification for a programming language independent system of modelling a formal grammar as data and a formal process for a universal, formal grammar independent parser that builds index overlay parse-trees. 

This allows to develop compilers purely by a grammar description and a interpreter for the resulting parse-tree. Parsing is decoupled from later analysis and emitter steps using pure data.
\end{abstract}
\section{Formal Grammar as Data}
Any formal grammar is modelled using the same universal data structure for all target languages. This data is \emph{interpreted} by universal solvers (e.g. a parser). No behaviour is attached to the grammar nor does it require to generate code for the production rules or the parse-tree.

\subsection{Composition of Rules}
A grammar is literally a set of production rules. Each production rule is composed out of \texttt{Rule} components. There is a fixed set of sufficient kinds of rules.
\begin{lstlisting}
type Grammar = [Rule]
data Rule
	= Literal UTF8String
	| Terminal [CodePointRange]
	| Pattern (UTF8String,Position) -> Length
	| Sequence [Rule]
	| Selection [Rule]
	| Iteration { r :: Rule, min :: Count, max :: Count }
	| Completion { subsequent :: Rule }
	| Capture Name Rule
	| Reference Name
data CodePointRange
	= Character CodePoint
	| NotCharacter CodePoint
	| Range { min :: CodePoint , max :: CodePoint }
	| NotRange { min :: CodePoint , max :: CodePoint }
type CodePoint = Word32
type UTF8String = [Word8]
type Position = Int32
type Length = Int32
type Name = String
type Count = Int
\end{lstlisting}
 The three terminal rules \texttt{Literal}, \texttt{Terminal} and \texttt{Pattern} match bytes or code-points of \texttt{UTF-8}. The non-terminal rules \texttt{Sequence}, \texttt{Selection}, \texttt{Iteration}, and \texttt{Completion} describe the nesting or structure of the syntax. A \texttt{Capture} decoration rule is used to name a rule for reference and as a node having that name in the resulting parse-tree. Finally the \texttt{Reference} allows the reuse of named rule components.

\subsection{Kinds of Rules}
\paragraph{Matching Bytes}
\begin{rulelist}
\item[Literal] Matches an exact sequence of UTF-8 bytes. Typical examples are keywords of the target language.

\item[Terminal] Matches ranges of UTF-8 code-points (any single character of the input within the range).

\item[Pattern] Matches an abstract pattern of UTF-8 bytes. The length of matching bytes is given through a function for a particular pattern. A pattern can match none, one or more bytes or code-points. This is the only building block that cannot be interpreted other than invoking the pattern function. Patterns are mostly used to more efficiently match common sequences like white-space.
\end{rulelist}

\paragraph{Matching Structure}
\begin{rulelist}
\item[Sequence] Wraps two or more components that have to sequentially follow each other. Matches if all its components match.

\item[Selection] Wraps two or more alternative components. The alternatives are ordered from highest to lowest priority. Matches as soon as highest yet tried component matches.

\item[Iteration] Decorates another rule and matches as long as the decorated rule matches at least as often as the specified minimum and at most as often as the specified maximum of occurrences.

\item[Completion] Is used within sequences to match up to the input position from which the subsequent rule component in the sequence matches.
\end{rulelist}

\paragraph{Reference and Parse-Tree}
\begin{rulelist}
\item[Capture] Decorates a rule and associates it with a grammar unique name. This names the rule component (for reference) and the resulting parse tree node at the same time. As long as the wrapped component matches an element a frame is pushed onto the parse tree stack describing start and end position, nesting level and rule of the matching component.
\end{rulelist}

\paragraph{Bootstrapping}
\begin{rulelist}
\item[Reference] Names the rule that this place-holder rule is substituted with when building the grammar. This allows to compose grammars programmatically and build rules having circular references to other rules. All references are replaced before a grammar is used. At runtime rules of this type do no longer occur.
\end{rulelist}

\section{Parser as Data Controlled Solver}
The universal parser is a solver that is controlled by the production rule data of a grammar. This way it interprets input documents and produces a index overlay parse-tree.

\subsection{Index Overlay Parse-Trees}
A parse-tree is modelled as a list of blocks. Each block results from a \texttt{Capture}. When processing input a \texttt{Block} "frame" is pushed onto the parse "stack" when it starts. As a result the list of blocks contains the root as its first element. 
\begin{lstlisting}
type ParseTree = [Block]
data Block = Block { 
	start :: Position,
	end :: Position,
	level :: Level,
	rule :: Rule
}
type Level = Word8
\end{lstlisting}
Each Block memorises the absolute \texttt{start} and \texttt{end} \texttt{Position} of the block in the input (byte offset), the nesting \texttt{level} (starting from 0 for the root and increasing towards the leafs) and the \texttt{rule} that is captured. 

The level is used to traverse the tree. For example in order to go to the next node all blocks with a higher level are skipped. The first block with the same or higher level as the starting one is the successor.

\paragraph{Note} In most languages the \texttt{Block} structure is better implemented as multiple arrays. That is one for all starts, ends, levels and rules where values at the same indexes are one logical block.

\section{Breaking with Conventional Wisdoms}
\subsection{Terminal and Non-Terminal Rules}
While there are kinds of rules that could be said to be terminal rules and other that could be said to be non-terminal ones this classification is neither necessary nor particular helpful as it is orthogonal to the concerns one has to reason about. Therefore this terms are avoided widely throughout the description. All rules are of the same type but different kinds. If there are groups to distinguish those are the kinds that match bytes or code-points and those that match the structure of the syntax.

\subsection{White-space}
White-space is considered to be meaningful and important content as it one of the variable parts of most syntaxes that humans do care about a lot. It is not stripped out and has to be matched explicitly. It is not different at all from any other content. A grammar's author can control whether or not it is captured in the same way other content is captured. Special \texttt{Pattern} rules are used to make matching white-space convenient again.

\subsection{Encoding}
The system of grammars as data and solvers could easily applied to any character encoding but it is the belief of the author that encodings are a major source of accidental complexity and have shown to be a common source of software defects that could be avoided. 

The \texttt{Unicode} standard might not be perfect but it is sufficient for universal usage. Out of the available \texttt{Unicode} encodings \texttt{UTF-8} balances the different objectives better than others and is already widely adopted. To emphasis the importance to use the same encoding everywhere the system is described particularly for \texttt{UTF-8}. A flexibility in the use of encodings is not a feature but a burden for both programmers and users.

\subsection{Code Generation}
Many of the popular parser-generators complect the grammar declaration with parse-tree or AST concerns. Code fragments are attached to the grammar definitions from which parser and AST code is generated. This clearly intermingles the concerns of parsing with those of analysis and code emitting and makes it impossible to share the same grammar declaration independent of the language the compiler is written in. 

The seconds major drawback is that a code generation step hinders  REPL-like feedback when working with the grammar. Even thou many tool have spent huge efforts in making grammar development smoothly none of the code generation tools could conveys a instant and interactive experience. 

Furthermore code generation renders direct runtime integrations impossible. Languages like Smalltalk would e.g. allow to have changes to the grammar directly effect the whole environment.

\subsection{Keywords}
There is no special notion or additional declaration for keywords in the system of grammars as data. This allows a grammar alone to be sufficient as a complete working definition of a language's syntax and parse-tree structure. As a consequence pure data can be exchanges e.g. in files to control solvers according to a language. For example code highlighters could be build once and feed with more languages from a grammar file alone.

\subsection{Precedence}
There are neither precedence rules nor different match modes as greedy/non-greedy. The first matching alternative of a \texttt{Selection} is considered the intended match. This fully intentionally limits the way a certain grammar can be expressed but does not disallow to embody any desired behaviour - a grammar just might need to be reshaped by the author. As a result the behaviour of a grammar is far more visible in a grammar's rules.

\end{document}